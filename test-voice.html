<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Transcription Test</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      max-width: 600px;
      margin: 50px auto;
      padding: 20px;
      background: #f5f5f5;
    }
    .container {
      background: white;
      border-radius: 10px;
      padding: 30px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    h1 {
      text-align: center;
      color: #333;
      margin-bottom: 30px;
    }
    button {
      display: block;
      width: 100%;
      padding: 15px 30px;
      font-size: 18px;
      background: #007bff;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      margin: 20px 0;
      transition: background 0.3s;
    }
    button:hover:not(:disabled) {
      background: #0056b3;
    }
    button:disabled {
      background: #ccc;
      cursor: not-allowed;
    }
    button.recording {
      background: #dc3545;
      animation: pulse 1.5s infinite;
    }
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }
    .status {
      text-align: center;
      margin: 20px 0;
      padding: 10px;
      border-radius: 5px;
      min-height: 30px;
    }
    .status.info {
      background: #e3f2fd;
      color: #1976d2;
    }
    .status.success {
      background: #e8f5e9;
      color: #388e3c;
    }
    .status.error {
      background: #ffebee;
      color: #c62828;
    }
    .transcription {
      margin-top: 20px;
      padding: 20px;
      background: #f8f9fa;
      border-radius: 5px;
      border-left: 4px solid #007bff;
      font-size: 16px;
      line-height: 1.6;
      min-height: 60px;
    }
    .transcription:empty::before {
      content: "Transcription will appear here...";
      color: #999;
    }
    .debug {
      margin-top: 20px;
      padding: 10px;
      background: #f0f0f0;
      border-radius: 5px;
      font-family: monospace;
      font-size: 12px;
      color: #666;
      max-height: 200px;
      overflow-y: auto;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è Voice Transcription Test</h1>
    
    <button id="recordButton">üé§ Start Recording</button>
    
    <div id="status" class="status"></div>
    
    <div id="transcription" class="transcription"></div>
    
    <div id="debug" class="debug"></div>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    
    const recordButton = document.getElementById('recordButton');
    const statusDiv = document.getElementById('status');
    const transcriptionDiv = document.getElementById('transcription');
    const debugDiv = document.getElementById('debug');
    
    function log(message) {
      const timestamp = new Date().toLocaleTimeString();
      debugDiv.innerHTML += `[${timestamp}] ${message}<br>`;
      debugDiv.scrollTop = debugDiv.scrollHeight;
    }
    
    function setStatus(message, type = 'info') {
      statusDiv.textContent = message;
      statusDiv.className = `status ${type}`;
    }
    
    async function startRecording() {
      try {
        log('Requesting microphone access...');
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        log('Microphone access granted');
        
        // Try to use WebM if supported, otherwise fall back to other formats
        const mimeType = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' :
                        MediaRecorder.isTypeSupported('audio/ogg') ? 'audio/ogg' :
                        'audio/wav';
        
        log(`Using MIME type: ${mimeType}`);
        
        mediaRecorder = new MediaRecorder(stream, { mimeType });
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
            log(`Audio chunk received: ${event.data.size} bytes`);
          }
        };
        
        mediaRecorder.onstop = async () => {
          log('Recording stopped, processing audio...');
          const audioBlob = new Blob(audioChunks, { type: mimeType });
          log(`Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
          
          // Stop all tracks to release the microphone
          stream.getTracks().forEach(track => track.stop());
          
          await sendAudioForTranscription(audioBlob);
        };
        
        mediaRecorder.start();
        isRecording = true;
        recordButton.textContent = '‚èπÔ∏è Stop Recording';
        recordButton.classList.add('recording');
        setStatus('Recording... Speak now!', 'info');
        log('Recording started');
        
      } catch (error) {
        console.error('Error starting recording:', error);
        log(`Error: ${error.message}`);
        setStatus(`Error: ${error.message}`, 'error');
      }
    }
    
    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        isRecording = false;
        recordButton.textContent = 'üé§ Start Recording';
        recordButton.classList.remove('recording');
        setStatus('Processing...', 'info');
        log('Stopping recording...');
      }
    }
    
    async function sendAudioForTranscription(audioBlob) {
      try {
        setStatus('Sending audio for transcription...', 'info');
        log(`Sending ${audioBlob.size} bytes to /api/transcribe`);
        log(`Content-Type: ${audioBlob.type}`);
        
        const response = await fetch('/api/transcribe', {
          method: 'POST',
          headers: {
            'Content-Type': audioBlob.type
          },
          body: audioBlob
        });
        
        log(`Response status: ${response.status} ${response.statusText}`);
        
        const data = await response.json();
        log(`Response data: ${JSON.stringify(data)}`);
        
        if (response.ok) {
          transcriptionDiv.textContent = data.transcription || 'No transcription returned';
          setStatus('Transcription complete!', 'success');
        } else {
          throw new Error(data.error || 'Transcription failed');
        }
        
      } catch (error) {
        console.error('Error sending audio:', error);
        log(`Error: ${error.message}`);
        setStatus(`Error: ${error.message}`, 'error');
        transcriptionDiv.textContent = '';
      }
      
      recordButton.disabled = false;
    }
    
    recordButton.addEventListener('click', () => {
      if (!isRecording) {
        recordButton.disabled = true;
        transcriptionDiv.textContent = '';
        debugDiv.innerHTML = '';
        startRecording().then(() => {
          recordButton.disabled = false;
        });
      } else {
        stopRecording();
      }
    });
    
    // Check browser support
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      setStatus('Your browser does not support audio recording', 'error');
      recordButton.disabled = true;
    } else {
      log('Browser supports audio recording');
      setStatus('Click the button to start recording', 'info');
    }
  </script>
</body>
</html>
